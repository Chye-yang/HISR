{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¥‡ Main Experiments ğŸ¥ˆğŸ¥‰\n",
    "\n",
    "ğŸ•¶ï¸ **To evaluate the frequency estimation performance, we compare our UCL-sketch with six baselines on four datasets.**\n",
    "\n",
    "- **Baselines** : `CM-sketch`, `C-sketch`, `Elastic Sketch`, `UnivMon`, `Nitrosketch`, `Learned CM-sketch`, and `Learned C-sketch`.\n",
    "\n",
    "- **Datasets** : *CAIDA*, *Retail*, *Kosarak*, and *Zipfian*\n",
    "\n",
    "- **Metrics** : *Average Absolute Error (AAE)*, *Average Relative Error (ARE)*, *Weighted Mean Relative Difference (WMRD)*, and *Entropy Absolute Error*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš„  Step 1 - Import necessary packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from load_data import readTraces\n",
    "from Sketching.unimon import UnivMon\n",
    "from Sketching.cs_sketch import Csketch\n",
    "from Sketching.cm_sketch import CMsketch\n",
    "from Utils.training import learningSolver\n",
    "from UCL_sketch.ucl_sketch import UCLSketch\n",
    "from Sketching.nitro_sketch import NitroSketch\n",
    "from Sketching.elastic_sketch import ElasticSketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¨ Step 2 - Configure your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Main Experiment')\n",
    "\n",
    "parser.add_argument('--data', type=str, default='network', help='data',\n",
    "                     choices=['retail', 'kosarak', 'network', 'synthetic'])\n",
    "parser.add_argument('--root_path', type=str, default='./data/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='test-8s.dat', help='data file',\n",
    "                    choices=['retail.dat', 'kosarak.dat', 'test-8s.dat', ''])\n",
    "parser.add_argument('--seed', type=int, default=12345, help='random seed')\n",
    "\n",
    "parser.add_argument('--slot_num', type=int, default=1200, help='Number of slots in the hash table')\n",
    "parser.add_argument('--bf_width', type=int, default=390000, help='Length of the Bloom Filter')\n",
    "parser.add_argument('--bf_hash', type=int, default=8, help='Number of used hash functions of the Bloom Filter')\n",
    "parser.add_argument('--key_size', type=int, default=13, help='KEY_T_SIZE')\n",
    "parser.add_argument('--hash_num', type=int, default=4, help='Number of used hash functions of the Sketch')\n",
    "parser.add_argument('--bucket_dim', type=int, default=512, help='Number of dimensions of each hash vector in the Sketch')\n",
    "parser.add_argument('--d_model', type=int, default=128, help='dimension of hidden states (d_model)')\n",
    "parser.add_argument('--break_number', type=int, default=1000000, help='number of stream data')\n",
    "parser.add_argument('--e_layers', type=int, default=0, help='Number of middle layers')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='dropout')\n",
    "parser.add_argument('--d_share', type=int, default=1024, help='length of the logical bucket')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints', help='location to store model checkpoints')\n",
    "\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='data loader num workers')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--train_epochs', type=int, default=300, help='train epochs')\n",
    "parser.add_argument('--patience', type=int, default=30, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3, help='optimizer initial learning rate')\n",
    "parser.add_argument('--lradj', type=str, default='type1',help='adjust learning rate')\n",
    "\n",
    "parser.add_argument('--save_pred', action='store_true', help='whether to save the estimated frequency', default=False)\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3',help='device ids of multile gpus')\n",
    "\n",
    "parser.add_argument('--interval', type=int, default=1000, help='sampling inserval')\n",
    "parser.add_argument('--num_samples', type=int, default=128, help='maintained samples (sliding window)')\n",
    "parser.add_argument('--ablation', type=int, default=0, help='ablational type')\n",
    "\n",
    "args = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "args.use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "    print(args.gpu)\n",
    "\n",
    "print(f\"Global seed set to {args.seed}\")\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Memory Usage -----\n",
      "Hash Table Size(Byte): 25221 (24.63 KB)\n",
      "Bloom Filter Size(Byte): 48751 (47.61 KB)\n",
      "CM Sketch Size(Byte): 16672 (16.28 KB)\n",
      "Total Memory(MB): 88.52 KB\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "ucl_sketch = UCLSketch(args.slot_num, args.bucket_dim, args.hash_num, args.bf_width, args.bf_hash, args.key_size)\n",
    "_ = ucl_sketch.get_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM-Sketch size: 160.84 KB\n",
      "C-Sketch size: 160.84 KB\n",
      "Nitro-Sketch size: 160.88 KB\n",
      "Elastic Sketch size: 127.24 KB\n",
      "UnivMon size: 192.25 KB\n"
     ]
    }
   ],
   "source": [
    "bucket_dim = 1024\n",
    "slot_num = 3500\n",
    "\n",
    "c_sketch = Csketch(bucket_dim*5, 4, args.key_size)\n",
    "lc_sketch = Csketch(bucket_dim*3, 4, args.key_size)\n",
    "cm_sketch = CMsketch(bucket_dim*5, 4, args.key_size)\n",
    "lcm_sketch = CMsketch(bucket_dim*3, 4, args.key_size)\n",
    "nitro_sketch = NitroSketch(bucket_dim*5, 4, args.key_size)\n",
    "elastic_sketch = ElasticSketch(slot_num//65, slot_num//100, bucket_dim*3, 4, args.key_size)\n",
    "univmon = UnivMon(2, bucket_dim*4, 4, args.key_size)\n",
    "\n",
    "ls = Csketch(bucket_dim*3, 4, args.key_size)\n",
    "\n",
    "print(f'CM-Sketch size: {(c_sketch.get_memory_usage() / (1024)):.2f} KB')\n",
    "print(f'C-Sketch size: {(cm_sketch.get_memory_usage() / (1024)):.2f} KB')\n",
    "print(f'Nitro-Sketch size: {(nitro_sketch.get_memory_usage() / (1024)):.2f} KB')\n",
    "print(f'Elastic Sketch size: {(elastic_sketch.get_memory_usage() / (1024)):.2f} KB')\n",
    "print(f'UnivMon size: {(univmon.get_memory_usage() / (1024)):.2f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â© Step 3 - Insert data stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¶…å‡ºé•¿åº¦éƒ¨åˆ†æˆªæ–­ï¼ˆæ€§èƒ½è€ƒè™‘ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in packets data...\n",
      "Successfully read in 3670738 items.\n"
     ]
    }
   ],
   "source": [
    "path = args.root_path + args.data_path\n",
    "# æ ¹è·¯å¾„./data/ æ•°æ®æ–‡ä»¶åtest-8s.dat\n",
    "size, traces = readTraces(path, args.data, args.key_size)\n",
    "\n",
    "if size > args.break_number:\n",
    "    traces = traces[:args.break_number]\n",
    "    size = args.break_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting packets into the sketch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000000/1000000 [00:50<00:00, 19893.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truthå·²å†™å…¥åˆ° ground_truth.txt\n",
      "ground_truth_1.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_2.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_3.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_4.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_5.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_6.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_7.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_8.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_9.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_10.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_11.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_12.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_13.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_14.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_15.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_16.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_17.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_18.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "ground_truth_19.txt å·²å†™å…¥åˆ° ground_truth_files\n",
      "æ‰€æœ‰ ground_truth æ•°æ®å·²åˆ†æ‰¹å†™å…¥åˆ° ground_truth_files ç›®å½•ä¸‹çš„ 19 ä¸ªæ–‡ä»¶ä¸­ã€‚\n",
      "Insert 1000000 items with 93703 distinct keys. Meanwhile, 129 points is sampled.\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–æ•°æ®åŒ…è®¡æ•°å™¨\n",
    "packetCnt = 0\n",
    "# åˆ›å»ºå­—å…¸å­˜å‚¨æ¯ä¸ªç½‘ç»œæµçš„çœŸå®é¢‘ç‡ï¼ˆground truthï¼‰\n",
    "ground_truth = {}\n",
    "# è®¡ç®—å¼€å§‹é‡‡æ ·çš„èµ·å§‹ä½ç½®ï¼šæ€»æ•°æ®é‡ - (é‡‡æ ·é—´éš” + 12) * é‡‡æ ·æ•°é‡\n",
    "sample_initial = size - (args.interval + 12) * args.num_samples\n",
    "\n",
    "# è®¾ç½®æ¡¶ç»´åº¦ä¸ºUCL-sketchä¸­CM-sketchçš„å®½åº¦\n",
    "args.bucket_dim = ucl_sketch.cm.width\n",
    "# åˆå§‹åŒ–é‡‡æ ·æ•°ç»„ï¼šå­˜å‚¨sketchçŠ¶æ€ï¼Œå½¢çŠ¶ä¸º[0, å“ˆå¸Œå‡½æ•°æ•°, æ¡¶ç»´åº¦]\n",
    "samples = np.empty([0, args.hash_num, args.bucket_dim])\n",
    "\n",
    "# ä½¿ç”¨è¿›åº¦æ¡éå†æ‰€æœ‰æ•°æ®åŒ…\n",
    "with tqdm(initial=0, total=size, desc='Inserting packets into the sketch') as pbar:\n",
    "    for idx, trace in enumerate(traces):\n",
    "        # ç»Ÿè®¡æ¯ä¸ªç½‘ç»œæµçš„å‡ºç°æ¬¡æ•°ï¼ˆæ„å»ºground truthï¼‰\n",
    "        if trace in ground_truth:\n",
    "            ground_truth[trace] += 1\n",
    "        else:\n",
    "            ground_truth[trace] = 1\n",
    "            \n",
    "        \n",
    "        # å°†å½“å‰ç½‘ç»œæµæ’å…¥åˆ°UCL-sketchä¸­\n",
    "        ucl_sketch.insert(trace)\n",
    "        packetCnt += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # åœ¨æŒ‡å®šä½ç½®å¼€å§‹é‡‡æ ·sketchçŠ¶æ€\n",
    "        if idx > sample_initial and idx % args.interval == 0:\n",
    "            # è·å–å½“å‰sketchçŠ¶æ€ï¼ˆä¸è¿”å›çŸ©é˜µAï¼‰\n",
    "            sample = ucl_sketch.get_current_state(return_A=False)\n",
    "            # å°†é‡‡æ ·ç»“æœæ·»åŠ åˆ°samplesæ•°ç»„ä¸­\n",
    "            samples = np.row_stack([samples, sample])\n",
    "\n",
    "# å°†ground truthä¿å­˜åˆ°å•ä¸ªæ–‡ä»¶\n",
    "gt_path = 'ground_truth.txt'\n",
    "with open(gt_path, 'w', encoding='utf-8') as f:\n",
    "    for key, value in ground_truth.items():\n",
    "        f.write(f'{key}\\t{value}\\n')\n",
    "print(f'ground_truthå·²å†™å…¥åˆ° {gt_path}')\n",
    "\n",
    "\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•ç”¨äºåˆ†æ‰¹ä¿å­˜ground truth\n",
    "output_dir = 'ground_truth_files'\n",
    "os.makedirs(output_dir, exist_ok=True) # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "\n",
    "# è®¾ç½®æ¯æ‰¹æ–‡ä»¶çš„å¤§å°\n",
    "batch_size = 5000\n",
    "file_count = 0\n",
    "current_batch_data = {}\n",
    "\n",
    "# åˆ†æ‰¹å¤„ç†ground truthæ•°æ®\n",
    "for key, value in ground_truth.items():\n",
    "    current_batch_data[key] = value\n",
    "    # å½“å½“å‰æ‰¹æ¬¡è¾¾åˆ°æŒ‡å®šå¤§å°æ—¶ï¼Œå†™å…¥æ–‡ä»¶\n",
    "    if len(current_batch_data) >= batch_size:\n",
    "        file_count += 1\n",
    "        gt_path = os.path.join(output_dir, f'ground_truth_{file_count}.txt')\n",
    "        with open(gt_path, 'w', encoding='utf-8') as f:\n",
    "            for k, v in current_batch_data.items():\n",
    "                f.write(f'{k}\\t{v}\\n')\n",
    "        print(f'ground_truth_{file_count}.txt å·²å†™å…¥åˆ° {output_dir}')\n",
    "        current_batch_data = {} # æ¸…ç©ºå½“å‰æ‰¹æ¬¡æ•°æ®\n",
    "\n",
    "# å¤„ç†æœ€åä¸€ä¸ªå¯èƒ½ä¸æ»¡ batch_size çš„æ‰¹æ¬¡\n",
    "if current_batch_data:\n",
    "    file_count += 1\n",
    "    gt_path = os.path.join(output_dir, f'ground_truth_{file_count}.txt')\n",
    "    with open(gt_path, 'w', encoding='utf-8') as f:\n",
    "        for k, v in current_batch_data.items():\n",
    "            f.write(f'{k}\\t{v}\\n')\n",
    "    print(f'ground_truth_{file_count}.txt å·²å†™å…¥åˆ° {output_dir}')\n",
    "\n",
    "print(f'æ‰€æœ‰ ground_truth æ•°æ®å·²åˆ†æ‰¹å†™å…¥åˆ° {output_dir} ç›®å½•ä¸‹çš„ {file_count} ä¸ªæ–‡ä»¶ä¸­ã€‚')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# æŒ‰é¢‘ç‡å¯¹ground truthè¿›è¡Œæ’åºï¼ˆä»å°åˆ°å¤§ï¼‰\n",
    "GT_sorted = sorted(ground_truth, key=lambda x: ground_truth[x])\n",
    "# è·å–é¢‘ç‡æœ€é«˜çš„topkä¸ªé”®ï¼ˆç”¨äºç†æƒ³å­¦ä¹ ç®—æ³•ï¼‰\n",
    "topk_keys = GT_sorted[- args.slot_num:]\n",
    "# è·å–å…¶ä½™çš„ä½é¢‘é”®\n",
    "GT_ideal = GT_sorted[:- args.slot_num]\n",
    "\n",
    "# å°†ä½é¢‘é”®æ’å…¥åˆ°å„ç§sketchä¸­ï¼ˆç”¨äºç†æƒ³å­¦ä¹ ç®—æ³•ï¼‰\n",
    "for key in GT_ideal:\n",
    "    value = ground_truth[key]\n",
    "    lc_sketch.insert(key, value)      # ç†æƒ³å­¦ä¹ C-sketch\n",
    "    lcm_sketch.insert(key, value)    # ç†æƒ³å­¦ä¹ CM-sketch\n",
    "    c_sketch.insert(key, value)      # æ™®é€šC-sketch\n",
    "    cm_sketch.insert(key, value)     # æ™®é€šCM-sketch\n",
    "    nitro_sketch.insert(key, value)  # Nitro-sketch\n",
    "    elastic_sketch.insert(key, value) # Elastic-sketch\n",
    "    univmon.insert(key, value)       # UnivMon\n",
    "\n",
    "# å°†é«˜é¢‘é”®ï¼ˆtopkï¼‰æ’å…¥åˆ°å„ç§sketchä¸­\n",
    "for key in topk_keys:\n",
    "    value = ground_truth[key]\n",
    "    c_sketch.insert(key, value)      # æ™®é€šC-sketch\n",
    "    cm_sketch.insert(key, value)     # æ™®é€šCM-sketch\n",
    "    nitro_sketch.insert(key, value)  # Nitro-sketch\n",
    "    elastic_sketch.insert(key, value) # Elastic-sketch\n",
    "    univmon.insert(key, value)       # UnivMon\n",
    "\n",
    "# è¾“å‡ºç»Ÿè®¡ä¿¡æ¯ï¼šæ’å…¥çš„æ•°æ®åŒ…æ•°ã€ä¸åŒé”®çš„æ•°é‡ã€é‡‡æ ·ç‚¹æ•°\n",
    "print(f'Insert {packetCnt} items with {len(ground_truth)} distinct keys. Meanwhile, {samples.shape[0]} points is sampled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºç»è¿‡ä¸‰ç»“æ„å¾—åˆ°çš„ CM-sketch è®¡æ•°å¿«ç…§ samples\n",
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "export_dir = 'export'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# 1) åŸå§‹å½¢çŠ¶ä¿å­˜ï¼š.npyï¼ˆä¿ç•™ [num_samples, hash_num, bucket_dim] ç»“æ„ï¼‰\n",
    "np.save(os.path.join(export_dir, 'cm_samples.npy'), samples)\n",
    "\n",
    "# 2) æ‰å¹³åŒ–ä¿å­˜ï¼š.csvï¼ˆæ¯ä¸€è¡Œæ˜¯ä¸€æ¬¡é‡‡æ ·ï¼ŒæŒ‰è¡Œä¼˜å…ˆå±•å¼€ depth*widthï¼‰\n",
    "cm_flat = samples.reshape(samples.shape[0], -1)\n",
    "np.savetxt(os.path.join(export_dir, 'cm_samples.csv'), cm_flat, delimiter=',', fmt='%d')\n",
    "\n",
    "# 3) å…ƒä¿¡æ¯ï¼šé‡‡æ ·æ•°é‡ä¸ç»´åº¦\n",
    "meta = {\n",
    "    'num_samples': int(samples.shape[0]),\n",
    "    'hash_num': int(samples.shape[1]),\n",
    "    'bucket_dim': int(samples.shape[2])\n",
    "}\n",
    "with open(os.path.join(export_dir, 'cm_samples_meta.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"CM-sketch é‡‡æ ·å·²å¯¼å‡ºï¼š{export_dir}/cm_samples.npy, cm_samples.csv, cm_samples_meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packetCnt = 0\n",
    "ground_truth = {}\n",
    "sample_initial = size - (args.interval + 12) * args.num_samples\n",
    "\n",
    "args.bucket_dim = ucl_sketch.cm.width\n",
    "samples = np.empty([0, args.hash_num, args.bucket_dim])\n",
    "\n",
    "with tqdm(initial=0, total=size, desc='Inserting packets into the sketch') as pbar:\n",
    "    for idx, trace in enumerate(traces):\n",
    "        if trace in ground_truth:\n",
    "            ground_truth[trace] += 1\n",
    "        else:\n",
    "            ground_truth[trace] = 1\n",
    "            \n",
    "        ucl_sketch.insert(trace)\n",
    "        packetCnt += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if idx > sample_initial and idx % args.interval == 0:\n",
    "            sample = ucl_sketch.get_current_state(return_A=False)\n",
    "            samples = np.row_stack([samples, sample])\n",
    "\n",
    "GT_sorted = sorted(ground_truth, key=lambda x: ground_truth[x])\n",
    "topk_keys = GT_sorted[- args.slot_num:]\n",
    "GT_ideal = GT_sorted[:- args.slot_num]\n",
    "\n",
    "for key in GT_ideal:\n",
    "    value = ground_truth[key]\n",
    "    lc_sketch.insert(key, value)\n",
    "    lcm_sketch.insert(key, value)\n",
    "    c_sketch.insert(key, value)\n",
    "    cm_sketch.insert(key, value)\n",
    "    nitro_sketch.insert(key, value)\n",
    "    elastic_sketch.insert(key, value)\n",
    "    univmon.insert(key, value)\n",
    "\n",
    "for key in topk_keys:\n",
    "    value = ground_truth[key]\n",
    "    c_sketch.insert(key, value)\n",
    "    cm_sketch.insert(key, value)\n",
    "    nitro_sketch.insert(key, value)\n",
    "    elastic_sketch.insert(key, value)\n",
    "    univmon.insert(key, value)\n",
    "\n",
    "print(f'Insert {packetCnt} items with {len(ground_truth)} distinct keys. Meanwhile, {samples.shape[0]} points is sampled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ å¸¦æ³¨é‡Šçš„ä»£ç ç‰ˆæœ¬\n",
    "# ä»¥ä¸‹æ˜¯ Cell 11 çš„è¯¦ç»†æ³¨é‡Šç‰ˆæœ¬\n",
    "\n",
    "packetCnt = 0  # åˆå§‹åŒ–æ•°æ®åŒ…è®¡æ•°å™¨\n",
    "ground_truth = {}  # åˆ›å»ºå­—å…¸å­˜å‚¨æ¯ä¸ªç½‘ç»œæµçš„çœŸå®é¢‘ç‡ï¼ˆground truthï¼‰\n",
    "sample_initial = size - (args.interval + 12) * args.num_samples  # è®¡ç®—å¼€å§‹é‡‡æ ·çš„èµ·å§‹ä½ç½®\n",
    "\n",
    "args.bucket_dim = ucl_sketch.cm.width  # è®¾ç½®æ¡¶ç»´åº¦ä¸ºUCL-sketchä¸­CM-sketchçš„å®½åº¦\n",
    "samples = np.empty([0, args.hash_num, args.bucket_dim])  # åˆå§‹åŒ–é‡‡æ ·æ•°ç»„ï¼šå­˜å‚¨sketchçŠ¶æ€\n",
    "\n",
    "with tqdm(initial=0, total=size, desc='Inserting packets into the sketch') as pbar:\n",
    "    for idx, trace in enumerate(traces):\n",
    "        if trace in ground_truth:  # ç»Ÿè®¡æ¯ä¸ªç½‘ç»œæµçš„å‡ºç°æ¬¡æ•°ï¼ˆæ„å»ºground truthï¼‰\n",
    "            ground_truth[trace] += 1\n",
    "        else:\n",
    "            ground_truth[trace] = 1\n",
    "            \n",
    "        \n",
    "        ucl_sketch.insert(trace)  # å°†å½“å‰ç½‘ç»œæµæ’å…¥åˆ°UCL-sketchä¸­\n",
    "        packetCnt += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if idx > sample_initial and idx % args.interval == 0:  # åœ¨æŒ‡å®šä½ç½®å¼€å§‹é‡‡æ ·sketchçŠ¶æ€\n",
    "            sample = ucl_sketch.get_current_state(return_A=False)  # è·å–å½“å‰sketchçŠ¶æ€ï¼ˆä¸è¿”å›çŸ©é˜µAï¼‰\n",
    "            samples = np.row_stack([samples, sample])  # å°†é‡‡æ ·ç»“æœæ·»åŠ åˆ°samplesæ•°ç»„ä¸­\n",
    "\n",
    "gt_path = 'ground_truth.txt'  # å°†ground truthä¿å­˜åˆ°å•ä¸ªæ–‡ä»¶\n",
    "with open(gt_path, 'w', encoding='utf-8') as f:\n",
    "    for key, value in ground_truth.items():\n",
    "        f.write(f'{key}\\t{value}\\n')\n",
    "print(f'ground_truthå·²å†™å…¥åˆ° {gt_path}')\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "output_dir = 'ground_truth_files'  # åˆ›å»ºè¾“å‡ºç›®å½•ç”¨äºåˆ†æ‰¹ä¿å­˜ground truth\n",
    "os.makedirs(output_dir, exist_ok=True) # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "\n",
    "batch_size = 5000  # è®¾ç½®æ¯æ‰¹æ–‡ä»¶çš„å¤§å°\n",
    "file_count = 0\n",
    "current_batch_data = {}\n",
    "\n",
    "for key, value in ground_truth.items():  # åˆ†æ‰¹å¤„ç†ground truthæ•°æ®\n",
    "    current_batch_data[key] = value\n",
    "    if len(current_batch_data) >= batch_size:  # å½“å½“å‰æ‰¹æ¬¡è¾¾åˆ°æŒ‡å®šå¤§å°æ—¶ï¼Œå†™å…¥æ–‡ä»¶\n",
    "        file_count += 1\n",
    "        gt_path = os.path.join(output_dir, f'ground_truth_{file_count}.txt')\n",
    "        with open(gt_path, 'w', encoding='utf-8') as f:\n",
    "            for k, v in current_batch_data.items():\n",
    "                f.write(f'{k}\\t{v}\\n')\n",
    "        print(f'ground_truth_{file_count}.txt å·²å†™å…¥åˆ° {output_dir}')\n",
    "        current_batch_data = {} # æ¸…ç©ºå½“å‰æ‰¹æ¬¡æ•°æ®\n",
    "\n",
    "# å¤„ç†æœ€åä¸€ä¸ªå¯èƒ½ä¸æ»¡ batch_size çš„æ‰¹æ¬¡\n",
    "if current_batch_data:\n",
    "    file_count += 1\n",
    "    gt_path = os.path.join(output_dir, f'ground_truth_{file_count}.txt')\n",
    "    with open(gt_path, 'w', encoding='utf-8') as f:\n",
    "        for k, v in current_batch_data.items():\n",
    "            f.write(f'{k}\\t{v}\\n')\n",
    "    print(f'ground_truth_{file_count}.txt å·²å†™å…¥åˆ° {output_dir}')\n",
    "\n",
    "print(f'æ‰€æœ‰ ground_truth æ•°æ®å·²åˆ†æ‰¹å†™å…¥åˆ° {output_dir} ç›®å½•ä¸‹çš„ {file_count} ä¸ªæ–‡ä»¶ä¸­ã€‚')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GT_sorted = sorted(ground_truth, key=lambda x: ground_truth[x])  # æŒ‰é¢‘ç‡å¯¹ground truthè¿›è¡Œæ’åºï¼ˆä»å°åˆ°å¤§ï¼‰\n",
    "topk_keys = GT_sorted[- args.slot_num:]  # è·å–é¢‘ç‡æœ€é«˜çš„topkä¸ªé”®ï¼ˆç”¨äºç†æƒ³å­¦ä¹ ç®—æ³•ï¼‰\n",
    "GT_ideal = GT_sorted[:- args.slot_num]  # è·å–å…¶ä½™çš„ä½é¢‘é”®\n",
    "\n",
    "for key in GT_ideal:  # å°†ä½é¢‘é”®æ’å…¥åˆ°å„ç§sketchä¸­ï¼ˆç”¨äºç†æƒ³å­¦ä¹ ç®—æ³•ï¼‰\n",
    "    value = ground_truth[key]\n",
    "    lc_sketch.insert(key, value)      # ç†æƒ³å­¦ä¹ C-sketch\n",
    "    lcm_sketch.insert(key, value)    # ç†æƒ³å­¦ä¹ CM-sketch\n",
    "    c_sketch.insert(key, value)      # æ™®é€šC-sketch\n",
    "    cm_sketch.insert(key, value)     # æ™®é€šCM-sketch\n",
    "    nitro_sketch.insert(key, value)  # Nitro-sketch\n",
    "    elastic_sketch.insert(key, value) # Elastic-sketch\n",
    "    univmon.insert(key, value)       # UnivMon\n",
    "\n",
    "for key in topk_keys:  # å°†é«˜é¢‘é”®ï¼ˆtopkï¼‰æ’å…¥åˆ°å„ç§sketchä¸­\n",
    "    value = ground_truth[key]\n",
    "    c_sketch.insert(key, value)      # æ™®é€šC-sketch\n",
    "    cm_sketch.insert(key, value)     # æ™®é€šCM-sketch\n",
    "    nitro_sketch.insert(key, value)  # Nitro-sketch\n",
    "    elastic_sketch.insert(key, value) # Elastic-sketch\n",
    "    univmon.insert(key, value)       # UnivMon\n",
    "\n",
    "print(f'Insert {packetCnt} items with {len(ground_truth)} distinct keys. Meanwhile, {samples.shape[0]} points is sampled.')  # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â›º Step 4 - Train the learning-based solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, index = ucl_sketch.get_current_state(return_A=True)\n",
    "solver = learningSolver(args, A.shape[1])\n",
    "solver.train(samples, A, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ï¼ˆå¯é€‰ï¼‰å¯¼å‡ºå½“å‰çš„ç¨€ç–æµ‹é‡çŸ©é˜µ A ä¸é”®ç´¢å¼• index\n",
    "# æ³¨æ„ï¼šA è·å–åœ¨è®­ç»ƒå‰ï¼ˆStep 4ï¼‰è°ƒç”¨ get_current_state(return_A=True)\n",
    "# å¦‚æœå°šæœªæ‰§è¡Œä¸Šä¸€æ­¥ï¼Œè¿™é‡Œä¼šå†æ¬¡è·å–ä¸€æ¬¡ä»¥ç¡®ä¿å¯å¯¼å‡º\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, save_npz\n",
    "\n",
    "export_dir = 'export'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    A  # å¦‚æœä¸Šä¸€æ­¥å·²å®šä¹‰\n",
    "    index  # å¦‚æœä¸Šä¸€æ­¥å·²å®šä¹‰\n",
    "except NameError:\n",
    "    # å…œåº•ï¼šå†æ¬¡è·å–\n",
    "    A, index = ucl_sketch.get_current_state(return_A=True)\n",
    "\n",
    "A_sparse = csr_matrix(A) if not hasattr(A, 'tocsr') else A.tocsr()\n",
    "save_npz(os.path.join(export_dir, 'A.npz'), A_sparse)\n",
    "np.save(os.path.join(export_dir, 'index.npy'), np.array(index, dtype=np.int32))\n",
    "\n",
    "print(f\"A ä¸ index å·²å¯¼å‡ºï¼š{export_dir}/A.npz, {export_dir}/index.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤” Step 5 - Per-key frequency query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'GT': [], 'UCL': [], 'ES': [], 'UM': [], 'CM': [],\n",
    "           'CS': [], 'NS': [], 'LCM': [], 'LCS': []}\n",
    "\n",
    "print('Querying for all keys ...')\n",
    "\n",
    "for key, value in ground_truth.items():\n",
    "    c_ans = c_sketch.query(key)\n",
    "    cm_ans = cm_sketch.query(key)\n",
    "    nitro_ans = nitro_sketch.query(key)\n",
    "    ela_ans = elastic_sketch.query(key)\n",
    "    uni_ans = univmon.query(key)\n",
    "\n",
    "    if key in topk_keys:\n",
    "        lc_ans = value\n",
    "        lcm_ans = value\n",
    "    else:\n",
    "        lc_ans = lc_sketch.query(key)\n",
    "        lcm_ans = lcm_sketch.query(key)\n",
    "\n",
    "    if ucl_sketch.cmResult == {}:\n",
    "        test_sample = ucl_sketch.get_current_state(return_A=False)\n",
    "        x = solver.test(test_sample)\n",
    "        x = np.ceil(x.squeeze()).astype(np.int32)\n",
    "\n",
    "    ucl_ans = ucl_sketch.query(key, x)\n",
    "\n",
    "    results['GT'].append(value)\n",
    "    results['UCL'].append(ucl_ans)\n",
    "    results['ES'].append(ela_ans)\n",
    "    results['UM'].append(uni_ans)\n",
    "    results['CM'].append(cm_ans)\n",
    "    results['CS'].append(c_ans)\n",
    "    results['NS'].append(nitro_ans)\n",
    "    results['LCM'].append(lcm_ans)\n",
    "    results['LCS'].append(lc_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ† Step 6 - Caculate related metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.mertrics import *\n",
    "\n",
    "GT = results['GT']\n",
    "\n",
    "AAE_R = []\n",
    "ARE_R = []\n",
    "WMRD_R = []\n",
    "EAE_R = []\n",
    "\n",
    "print('Performace of UCL-sketch:')\n",
    "ET = results['UCL']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)\n",
    "\n",
    "print('Performace of CM-sketch:')\n",
    "ET = results['CM']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)\n",
    "\n",
    "print('Performace of C-sketch:')\n",
    "ET = results['CS']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)\n",
    "\n",
    "print('Performace of Ideally Learned CM-sketch:')\n",
    "ET = results['LCM']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)\n",
    "\n",
    "print('Performace of Ideally Learned C-sketch:')\n",
    "ET = results['LCS']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)\n",
    "\n",
    "print('Performace of Elastic Sketch:')\n",
    "ET = results['ES']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)\n",
    "\n",
    "print('Performace of UnivMon:')\n",
    "ET = results['UM']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)\n",
    "\n",
    "print('Performace of NitroSketch:')\n",
    "ET = results['NS']\n",
    "AAE = average_absolute_error(GT, ET)\n",
    "ARE = average_relative_error(GT, ET)\n",
    "WMRD = weighted_mean_relative_difference(GT, ET)\n",
    "EAE = entropy_absolute_error(GT, ET)\n",
    "print(f'â€”â€” AAE: {AAE:.4f}, ARE: {ARE:.4f}, WMRD: {WMRD:.4f}, and Entropy Absolute Error: {EAE:.4f}')\n",
    "AWE = average_weighted_error(GT, ET)\n",
    "\n",
    "AAE_R.append(int(AAE*100)/100)\n",
    "ARE_R.append(int(ARE*100)/100)\n",
    "WMRD_R.append(int(WMRD*100)/100)\n",
    "EAE_R.append(int(EAE*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¶ Step 7 - Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(15, 9))\n",
    "\n",
    "width = 0.5\n",
    "x_n = ['UCL', 'CM', 'CS', 'LCM', 'LCS', 'ES', 'UM', 'NS']\n",
    "x = np.arange(len(x_n))\n",
    "\n",
    "ax1.bar(x, AAE_R, width=width, edgecolor='k')\n",
    "ax1.set_xticks(x, labels=x_n, fontproperties='Times New Roman', fontsize=12)\n",
    "ax1.set_ylabel('AAE', fontdict={'family': 'Times New Roman', 'size': 18})\n",
    "ax1.tick_params('both', labelsize=12)\n",
    "ax1.grid(axis='y', linestyle='-.', lw=0.75)\n",
    "\n",
    "ax2.bar(x, ARE_R, width=width, edgecolor='k')\n",
    "ax2.set_xticks(x, labels=x_n, fontproperties='Times New Roman', fontsize=12)\n",
    "ax2.set_ylabel('ARE', fontdict={'family': 'Times New Roman', 'size': 18})\n",
    "ax2.tick_params('both', labelsize=12)\n",
    "ax2.grid(axis='y', linestyle='-.', lw=0.75)\n",
    "\n",
    "ax3.bar(x, WMRD_R, width=width, edgecolor='k')\n",
    "ax3.set_xticks(x, labels=x_n, fontproperties='Times New Roman', fontsize=12)\n",
    "ax3.set_ylabel('WMRD', fontdict={'family': 'Times New Roman', 'size': 18})\n",
    "ax3.tick_params('both', labelsize=12)\n",
    "ax3.grid(axis='y', linestyle='-.', lw=0.5)\n",
    "\n",
    "ax4.bar(x, EAE_R, width=width, edgecolor='k')\n",
    "ax4.set_xticks(x, labels=x_n, fontproperties='Times New Roman', fontsize=12)\n",
    "ax4.set_ylabel('Entropy Absolute Error', fontdict={'family': 'Times New Roman', 'size': 18})\n",
    "ax4.tick_params('both', labelsize=12)\n",
    "ax4.grid(axis='y', linestyle='-.', lw=0.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
